{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# General overview of the game we play in machine learning.\n",
    "- Nature generates data according to some function $f:x \\rightarrow y$ we don't know\n",
    "- In machine learning we want a good approximation of f on out of sample data.\n",
    "- We start with set of possible functions(Hypothesis space $\\mathcal{H}$) and try to pick a function $\\hat{f}$ best approximating true f(which we don't know)\n",
    "    + Complex $\\mathcal{H} $ means  good chance of approximating $f$ but hard to find approximation?\n",
    "    + Simple $\\mathcal{H}$ means good generalization on out of sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias variance analysis effectively asks following questions.\n",
    "- How well $\\mathcal{H}$ can approximate $f$ overall.\n",
    "- Given the sample how good is our approximation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use square error analysis on linear regression\n",
    "Let's say f is true function and $\\hat(f)$ is our choice of target function based on sample dataset $\\mathcal{D}$  in hypothesis space $\\mathcal{H}$\n",
    "Then\n",
    "\n",
    "  $E_{out}(\\hat{f}_{\\mathcal{D}}) = \\mathbb{E}_{x}(\\hat{f}_{\\mathcal{D}}(x) -f(x))^2$\n",
    " \n",
    " This depends on a particular sample $\\mathcal{D}$. If we take another same number of sample this will change.\n",
    " To do error anlysis we need to get rid of a particular sample $\\mathcal{D}$ choice.\n",
    " \n",
    " Let's take expectation with respect to distriution  over $\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " $\\begin{align} \\mathbb{E_{\\mathcal{D}}}(E_{out}(\\hat{f}_{\\mathcal{D}})) &=  \\mathbb{E_{\\mathcal{D}}}\\mathbb{E}_{x}(\\hat{f}_{\\mathcal{D}}(x) -f(x))^2 \\\\\n",
    " & = \\mathbb{E}_{x}\\mathbb{E}_{\\mathcal{D}}(\\hat{f}_{\\mathcal{D}}(x) -f(x))^2  \n",
    " \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Define average hypothesis\n",
    "\n",
    "$$ \\bar{f} = \\mathbb{E}_{\\mathcal{D}}(\\hat{f}_{\\mathcal{D}}(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\begin{align}  \\mathbb{E}_{\\mathcal{D}}(\\hat{f}_{\\mathcal{D}}(x) -f(x))^2  \n",
    " & = \\mathbb{E}_{\\mathcal{D}}[\\hat{f}_{\\mathcal{D}}(x) -\\bar{f}(x) +\\bar{f}(x)  -f(x)]^2 \\\\\n",
    " &= \\mathbb{E}_{\\mathcal{D}} [ (\\hat{f}_{\\mathcal{D}}(x) -\\bar{f}(x))^2 + (\\bar{f}(x)  -f(x))^2) +2(\\hat{f}_{\\mathcal{D}}(x) -\\bar{f}(x)) (\\bar{f}(x)  -f(x))]\\\\\n",
    " &= \\mathbb{E}_{\\mathcal{D}} [ (\\hat{f}_{\\mathcal{D}}(x) -\\bar{f}(x))^2] + [\\bar{f}(x)  -f(x)]^2 \n",
    " \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\underbrace{\\mathbb{E}_{\\mathcal{D}} [ (\\hat{f}_{\\mathcal{D}}(x)}_\\text{variance(x)} -\\bar{f}(x))^2] + \\underbrace{[\\bar{f}(x)  -f(x)]^2}_\\text{bias(x)} $\n",
    "\n",
    "bias =  a measure of best we can do in our hypothesis set\n",
    "\n",
    "variance = how far our hypothesis based on $\\mathcal{D}$ is away from average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\begin{align} \\mathbb{E}_{x}\\mathbb{E}_{\\mathcal{D}}(\\hat{f}_{\\mathcal{D}}(x) -f(x))^2 \n",
    "&= \\mathbb{E}_x[\\mathbb{E}_{\\mathcal{D}} [ (\\hat{f}_{\\mathcal{D}}(x) -\\bar{f}(x))^2] + [\\bar{f}(x)  -f(x)]^2]\\\\\n",
    "&= \\mathbb{E}_x[ bias^2(x) + variance(x)] \\\\\n",
    "&= bias^2 + variance\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<img src=\"bias_variance.jpeg\" alt=\"bias variance \" width=\"1000\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"bias_variance_c.jpeg\" alt=\"train val test\" width=\"1000\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"under_over.jpeg\" alt=\"train val test\" width=\"1000\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation of Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need a way to measure how well learning algorithm perfroms.\n",
    "Till now we have seen follwoing measures\n",
    "\n",
    "- Accuracy\n",
    "- Precision, Recall, ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# let's make it more formal\n",
    "- Given an Hypothesis space $\\mathcal{H}$, using training data $\\mathcal{D}$ we select a hypothesis $\\hat{f} \\in \\mathcal{H}$\n",
    "- Given a feature vector $x$ we  predict using $h$ as $\\hat{y} =\\hat{f}(x)$. Let say true value is $y.$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For Regresssion \n",
    "\n",
    "- MAE (Mean absolute error)  $  \\frac{\\sum_i^N|\\hat{f}(x_i) -y_i|}{N}$\n",
    "- MSE (Mean square error)  $\\frac{\\sum_i^N\\|\\hat{f}(x_i) -y_i\\|^2}{N}$\n",
    "## For Classification\n",
    " - Miss classification error =    $\\frac{\\sum_i^N\\mathbb{I}(\\hat{f}(x_i) \\ne y_i)}{N}$\n",
    " - Build Confusion matrix, Remember TP, TN, FP, FN for binary calssification. You can build confusion matrix \n",
    " for K class classification too.\n",
    " - ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Confusion Matrix for a particular value of threshold $\\tau$\n",
    "|       | $y=1$           | $y=0$  |     |\n",
    "| ------------- |:-------------:| -----:|:---|\n",
    "| $\\hat{y}$=1      | TP |FP | $\\hat{N}_{+}$ = TP + FN   |    |\n",
    "| $\\hat{y}$=0      | FN      |   TN |     $\\hat{N}_{-}$ = TN + FN|\n",
    "|------------- |:-------------:| -----:|:-----|\n",
    "|    | $N_{+}$ = TP + FN    |  $N_{-}$ = TN + FP   | N= TP+FN +TN+FP    |\n",
    "\n",
    "precision = $\\frac{TP}{TP+FP}$\n",
    "\n",
    "recall = True positive rate(**TPR**) = $\\frac{TP}{N_+} \\approx p(\\hat{y} =1| y =1)$\n",
    "\n",
    "false positive rate (**FPR**)(type I error rate) = $\\frac{FP}{N_{-}} \\approx p(\\hat{y} =1| y =0)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample error vs True Error(In classification setting)\n",
    "**Sample error** : The sample error of a  hypothesis $\\hat{f}(x)$  with respect to true function(target) $f$\n",
    "on a sample $\\mathcal{D} = \\{x_i, y_i = f(x_i) \\}_{i=1}^{i=N}$  is miss classification error  $\\frac{\\sum_i^N\\mathbb{I}(\\hat{f}(x_i) \\ne f(x_i))}{N}$\n",
    "\n",
    "**True Error** The true error of a  hypothesis $\\hat{f}(x)$  with respect to true function(target) $f$\n",
    " and distribution $P$, is the probability of mis classifying a random sample from distrubtion $P$, $Pr_{x \\sim P} [\\hat{f}(x) \\ne f(x)]$\n",
    " \n",
    " We need good  **True Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Evaluation of hypothesis under limited sample data\n",
    "\n",
    "- Split the samples into train and test\n",
    "<img src=\"train_val_test.jpeg\" alt=\"train val test\" width=\"1000\" height=\"1000\">\n",
    "\n",
    "What if train set is too small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- we have small samples size.\n",
    "- Can't touch test set\n",
    "- Can we use data in validation for training too?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "yes. Procedure is calls k -fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"kfold.jpeg\" alt=\"train val test\" width=\"1000\" height=\"1000\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
